{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":376298,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":310884,"modelId":331250},{"sourceId":380003,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":314039,"modelId":334454},{"sourceId":382733,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":316022,"modelId":336491}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Audio to Text**","metadata":{"id":"rlrWdCoJf2ps"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:24:47.915628Z","iopub.execute_input":"2025-05-08T17:24:47.915895Z","iopub.status.idle":"2025-05-08T17:24:47.919621Z","shell.execute_reply.started":"2025-05-08T17:24:47.915873Z","shell.execute_reply":"2025-05-08T17:24:47.918912Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!sudo apt update && sudo apt install ffmpeg","metadata":{"id":"rUZqQuJ1f-cA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3fcf1446-bd05-4c15-a563-3ffbfba9d7f7","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:24:57.153527Z","iopub.execute_input":"2025-05-08T17:24:57.153811Z","iopub.status.idle":"2025-05-08T17:25:04.593639Z","shell.execute_reply.started":"2025-05-08T17:24:57.153790Z","shell.execute_reply":"2025-05-08T17:25:04.592847Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [77.5 kB]\u001b[33m\u001b[33m\nGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \u001b[0m\u001b[33m\u001b[33m\nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                         \u001b[0m\u001b[33m\nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \u001b[0m\nGet:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,665 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \u001b[0m\u001b[33m\u001b[33m\nGet:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,720 kB]\u001b[0m\u001b[33m\nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]m\u001b[33m\nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,926 kB] \u001b[0m\u001b[33m\u001b[33m\u001b[33m\nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]     \u001b[0m\u001b[33m\nGet:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\nHit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \u001b[0m\nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,436 kB]33m\u001b[33m\nGet:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.2 kB]\nGet:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.3 kB]\nGet:19 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]3m\u001b[33m\nGet:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,282 kB]\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,901 kB]3m\u001b[33m\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,211 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nFetched 31.7 MB in 3s (11.3 MB/s)[33m                         \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n159 packages can be upgraded. Run 'apt list --upgradable' to see them.\n\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 159 not upgraded.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git","metadata":{"id":"fmc4_t2ff-Q4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1f86fa50-f30b-41fd-ee0e-4e77835ff4d0","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:25:04.595260Z","iopub.execute_input":"2025-05-08T17:25:04.595568Z","iopub.status.idle":"2025-05-08T17:25:14.555948Z","shell.execute_reply.started":"2025-05-08T17:25:04.595545Z","shell.execute_reply":"2025-05-08T17:25:14.555191Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-zt79cw4z\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-zt79cw4z\n  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\nRequirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.18.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper==20240930) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper==20240930) (2024.2.0)\nBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803706 sha256=103c380c5d2708b2170fb91087a1d7222bd444028b41d579efd00653c03c8762\n  Stored in directory: /tmp/pip-ephem-wheel-cache-m4oeos48/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\nSuccessfully built openai-whisper\nInstalling collected packages: openai-whisper\nSuccessfully installed openai-whisper-20240930\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import whisper\n#Load the Whisper model\nmodel = whisper.load_model(\"large\")","metadata":{"id":"FEmPUoAVf-GN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7141d13-b7f9-4fe4-dcce-584aebe72edf","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:25:14.557112Z","iopub.execute_input":"2025-05-08T17:25:14.557711Z","iopub.status.idle":"2025-05-08T17:26:43.688945Z","shell.execute_reply.started":"2025-05-08T17:25:14.557676Z","shell.execute_reply":"2025-05-08T17:26:43.688094Z"}},"outputs":[{"name":"stderr","text":"100%|█████████████████████████████████████| 2.88G/2.88G [00:59<00:00, 52.2MiB/s]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\nimport subprocess\n\nvideo_file = \"/kaggle/input/introml/transformers/default/1/Machine Learning 1 - Lab 01.mp4\"  # اسم الفيديو اللي هتشتغل عليه\n\n\naudio_dir = \"audio\"  #فولدرات الإخراج\nos.makedirs(audio_dir, exist_ok=True) # إنشاء الفولدرات لو مش موجودة\n\n\ndef extract_audio(video_path, output_dir):\n    audio_output = os.path.join(output_dir, \"audio.wav\")\n    cmd = [\n        \"ffmpeg\",\n        \"-i\", video_path,\n        \"-q:a\", \"0\",\n        \"-map\", \"a\",\n        audio_output\n    ]\n    subprocess.run(cmd, check=True)\n    print(f\"audio extracted successfully: {audio_output}\")\n    return audio_output\n\n\ntry:\n    extract_audio(video_file, audio_dir)\nexcept Exception as e:\n    print(f\"fail in extract audio: {e}\")\n","metadata":{"id":"tudICuP1f97i","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60a324c6-db5d-4a39-82d8-2d8294630343","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:26:43.691343Z","iopub.execute_input":"2025-05-08T17:26:43.691588Z","iopub.status.idle":"2025-05-08T17:26:56.025544Z","shell.execute_reply.started":"2025-05-08T17:26:43.691570Z","shell.execute_reply":"2025-05-08T17:26:56.024869Z"}},"outputs":[{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from '/kaggle/input/introml/transformers/default/1/Machine Learning 1 - Lab 01.mp4':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2\n    creation_time   : 2022-04-01T11:19:04.000000Z\n  Duration: 02:39:38.62, start: 0.000000, bitrate: 390 kb/s\n  Stream #0:0(eng): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 1920x1080, 321 kb/s, 14.99 fps, 15 tbr, 10k tbn, 20k tbc (default)\n    Metadata:\n      creation_time   : 2022-04-01T11:19:04.000000Z\n      vendor_id       : [0][0][0][0]\n  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 66 kb/s (default)\n    Metadata:\n      creation_time   : 2022-04-01T11:19:04.000000Z\n      vendor_id       : [0][0][0][0]\nStream mapping:\n  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'audio/audio.wav':\n  Metadata:\n    major_brand     : isom\n    minor_version   : 512\n    compatible_brands: isomiso2\n    ISFT            : Lavf58.76.100\n  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n    Metadata:\n      creation_time   : 2022-04-01T11:19:04.000000Z\n      vendor_id       : [0][0][0][0]\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=  299332kB time=02:39:38.56 bitrate= 256.0kbits/s speed= 818x    \nvideo:0kB audio:299332kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000025%\n","output_type":"stream"},{"name":"stdout","text":"audio extracted successfully: audio/audio.wav\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"mkdir audio_segments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:26:56.026186Z","iopub.execute_input":"2025-05-08T17:26:56.026393Z","iopub.status.idle":"2025-05-08T17:26:56.306805Z","shell.execute_reply.started":"2025-05-08T17:26:56.026376Z","shell.execute_reply":"2025-05-08T17:26:56.305836Z"}},"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘audio_segments’: File exists\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"!ffmpeg -i \"/kaggle/working/audio/audio.wav\" -f segment -segment_time 300 -ar 16000 -ac 1 -vn audio_segments/segment_%03d.wav","metadata":{"id":"hl8RYBW_gjOu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70fce77c-4937-4ae7-b670-c19667bede13","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:26:56.307918Z","iopub.execute_input":"2025-05-08T17:26:56.308196Z","iopub.status.idle":"2025-05-08T17:26:57.991481Z","shell.execute_reply.started":"2025-05-08T17:26:56.308172Z","shell.execute_reply":"2025-05-08T17:26:57.990501Z"}},"outputs":[{"name":"stdout","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n\u001b[0mInput #0, wav, from '/kaggle/working/audio/audio.wav':\n  Metadata:\n    encoder         : Lavf58.76.100\n  Duration: 02:39:38.62, bitrate: 256 kb/s\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\nStream mapping:\n  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_000.wav' for writing\nOutput #0, segment, to 'audio_segments/segment_%03d.wav':\n  Metadata:\n    encoder         : Lavf58.76.100\n  Stream #0:0: Audio: pcm_s16le, 16000 Hz, mono, s16, 256 kb/s\n    Metadata:\n      encoder         : Lavc58.134.100 pcm_s16le\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_001.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_002.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_003.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_004.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_005.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_006.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_007.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_008.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_009.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_010.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_011.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_012.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_013.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_014.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_015.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_016.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_017.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_018.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_019.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_020.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_021.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_022.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_023.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_024.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_025.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_026.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_027.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_028.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_029.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_030.wav' for writing\n\u001b[1;35m[segment @ 0x5649aea447c0] \u001b[0mOpening 'audio_segments/segment_031.wav' for writing\nsize=N/A time=02:39:38.49 bitrate=N/A speed=7.34e+03x    \nvideo:0kB audio:299332kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import glob\nimport os\n\naudio_segments_path = \"audio_segments/\"\nos.makedirs(audio_segments_path, exist_ok=True)\n\n# Get list of all audio segment files\naudio_files = sorted(glob.glob(f\"{audio_segments_path}/segment_*.wav\"))\n\n# Process each audio file\nfor audio_file in audio_files:\n    print(f\"Processing {audio_file}...\")\n    try:\n        # Transcribe the audio file\n        result = model.transcribe(audio_file)\n\n        # Save transcription\n        output_file = f\"{audio_file}.txt\"\n        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n            f.write(result[\"text\"])\n        print(f\"Transcription for {audio_file} saved to {output_file}.\")\n    except Exception as e:\n        print(f\"Error processing {audio_file}: {e}\")","metadata":{"id":"leoS4trdgjJl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5504be94-7035-477b-9870-131aaf710b6a","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:58:59.535818Z","iopub.execute_input":"2025-05-08T17:58:59.536226Z","iopub.status.idle":"2025-05-08T19:04:45.369249Z","shell.execute_reply.started":"2025-05-08T17:58:59.536206Z","shell.execute_reply":"2025-05-08T19:04:45.368402Z"}},"outputs":[{"name":"stdout","text":"Processing audio_segments/segment_000.wav...\nTranscription for audio_segments/segment_000.wav saved to audio_segments/segment_000.wav.txt.\nProcessing audio_segments/segment_001.wav...\nTranscription for audio_segments/segment_001.wav saved to audio_segments/segment_001.wav.txt.\nProcessing audio_segments/segment_002.wav...\nTranscription for audio_segments/segment_002.wav saved to audio_segments/segment_002.wav.txt.\nProcessing audio_segments/segment_003.wav...\nTranscription for audio_segments/segment_003.wav saved to audio_segments/segment_003.wav.txt.\nProcessing audio_segments/segment_004.wav...\nTranscription for audio_segments/segment_004.wav saved to audio_segments/segment_004.wav.txt.\nProcessing audio_segments/segment_005.wav...\nTranscription for audio_segments/segment_005.wav saved to audio_segments/segment_005.wav.txt.\nProcessing audio_segments/segment_006.wav...\nTranscription for audio_segments/segment_006.wav saved to audio_segments/segment_006.wav.txt.\nProcessing audio_segments/segment_007.wav...\nTranscription for audio_segments/segment_007.wav saved to audio_segments/segment_007.wav.txt.\nProcessing audio_segments/segment_008.wav...\nTranscription for audio_segments/segment_008.wav saved to audio_segments/segment_008.wav.txt.\nProcessing audio_segments/segment_009.wav...\nTranscription for audio_segments/segment_009.wav saved to audio_segments/segment_009.wav.txt.\nProcessing audio_segments/segment_010.wav...\nTranscription for audio_segments/segment_010.wav saved to audio_segments/segment_010.wav.txt.\nProcessing audio_segments/segment_011.wav...\nTranscription for audio_segments/segment_011.wav saved to audio_segments/segment_011.wav.txt.\nProcessing audio_segments/segment_012.wav...\nTranscription for audio_segments/segment_012.wav saved to audio_segments/segment_012.wav.txt.\nProcessing audio_segments/segment_013.wav...\nTranscription for audio_segments/segment_013.wav saved to audio_segments/segment_013.wav.txt.\nProcessing audio_segments/segment_014.wav...\nTranscription for audio_segments/segment_014.wav saved to audio_segments/segment_014.wav.txt.\nProcessing audio_segments/segment_015.wav...\nTranscription for audio_segments/segment_015.wav saved to audio_segments/segment_015.wav.txt.\nProcessing audio_segments/segment_016.wav...\nTranscription for audio_segments/segment_016.wav saved to audio_segments/segment_016.wav.txt.\nProcessing audio_segments/segment_017.wav...\nTranscription for audio_segments/segment_017.wav saved to audio_segments/segment_017.wav.txt.\nProcessing audio_segments/segment_018.wav...\nTranscription for audio_segments/segment_018.wav saved to audio_segments/segment_018.wav.txt.\nProcessing audio_segments/segment_019.wav...\nTranscription for audio_segments/segment_019.wav saved to audio_segments/segment_019.wav.txt.\nProcessing audio_segments/segment_020.wav...\nTranscription for audio_segments/segment_020.wav saved to audio_segments/segment_020.wav.txt.\nProcessing audio_segments/segment_021.wav...\nTranscription for audio_segments/segment_021.wav saved to audio_segments/segment_021.wav.txt.\nProcessing audio_segments/segment_022.wav...\nTranscription for audio_segments/segment_022.wav saved to audio_segments/segment_022.wav.txt.\nProcessing audio_segments/segment_023.wav...\nTranscription for audio_segments/segment_023.wav saved to audio_segments/segment_023.wav.txt.\nProcessing audio_segments/segment_024.wav...\nTranscription for audio_segments/segment_024.wav saved to audio_segments/segment_024.wav.txt.\nProcessing audio_segments/segment_025.wav...\nTranscription for audio_segments/segment_025.wav saved to audio_segments/segment_025.wav.txt.\nProcessing audio_segments/segment_026.wav...\nTranscription for audio_segments/segment_026.wav saved to audio_segments/segment_026.wav.txt.\nProcessing audio_segments/segment_027.wav...\nTranscription for audio_segments/segment_027.wav saved to audio_segments/segment_027.wav.txt.\nProcessing audio_segments/segment_028.wav...\nTranscription for audio_segments/segment_028.wav saved to audio_segments/segment_028.wav.txt.\nProcessing audio_segments/segment_029.wav...\nTranscription for audio_segments/segment_029.wav saved to audio_segments/segment_029.wav.txt.\nProcessing audio_segments/segment_030.wav...\nTranscription for audio_segments/segment_030.wav saved to audio_segments/segment_030.wav.txt.\nProcessing audio_segments/segment_031.wav...\nTranscription for audio_segments/segment_031.wav saved to audio_segments/segment_031.wav.txt.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"with open(\"full_transcription.txt\", \"w\", encoding=\"utf-8\") as outfile:\n    for audio_file in audio_files:\n        segment_file = f\"{audio_file}.txt\"\n        with open(segment_file, \"r\", encoding=\"utf-8\") as infile:\n            outfile.write(infile.read() + \"\\n\")\n\nprint(\"Combined transcription saved to 'full_transcription.txt'.\")","metadata":{"id":"Pz3ppkELgjGI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a732af5-0fd2-473c-d6f1-ba520475042c","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:14.830318Z","iopub.execute_input":"2025-05-08T19:19:14.830914Z","iopub.status.idle":"2025-05-08T19:19:14.839364Z","shell.execute_reply.started":"2025-05-08T19:19:14.830886Z","shell.execute_reply":"2025-05-08T19:19:14.838504Z"}},"outputs":[{"name":"stdout","text":"Combined transcription saved to 'full_transcription.txt'.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"# **Summarization**","metadata":{"id":"-uG8pKZ4fKA7"}},{"cell_type":"code","source":"!pip install pypdf langchain_groq langchain_openai langchain langchain_huggingface openai faiss-cpu langchain-community langdetect -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVfV1ND18HV2","outputId":"f57d68ec-0ad9-43b7-e39c-40ef0c0cc2d8","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:14.840529Z","iopub.execute_input":"2025-05-08T19:19:14.840751Z","iopub.status.idle":"2025-05-08T19:19:18.369179Z","shell.execute_reply.started":"2025-05-08T19:19:14.840728Z","shell.execute_reply":"2025-05-08T19:19:18.368187Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from openai import OpenAI\nimport os\nimport groq\nfrom langchain_groq import ChatGroq\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain","metadata":{"id":"E3QwUf4j8H7H","colab":{"base_uri":"https://localhost:8080/","height":399},"outputId":"b9450b63-744a-4921-83ce-fdc73606ca0f","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.370380Z","iopub.execute_input":"2025-05-08T19:19:18.370813Z","iopub.status.idle":"2025-05-08T19:19:18.375664Z","shell.execute_reply.started":"2025-05-08T19:19:18.370776Z","shell.execute_reply":"2025-05-08T19:19:18.374742Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"user_key =\"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\"\nllm = ChatGroq(\n    groq_api_key=user_key,\n    model_name=\"deepseek-r1-distill-llama-70b\"\n)","metadata":{"id":"5klWcea38H92","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.377595Z","iopub.execute_input":"2025-05-08T19:19:18.377795Z","iopub.status.idle":"2025-05-08T19:19:18.499729Z","shell.execute_reply.started":"2025-05-08T19:19:18.377780Z","shell.execute_reply":"2025-05-08T19:19:18.498997Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import re\n\ndef summarize_text_English(text, llm):\n    prompt = (f\"Summarize the following text efficiently, providing only the existing key insights in English without adding any additional information: \\n{text}\")\n    try:\n        response = llm.invoke(prompt)\n\n        # Access and clean the response content\n        if hasattr(response, 'content'):\n            raw_summary = response.content  # Extract content\n            cleaned_summary = re.sub(r\"<think>.*?</think>\", \"\", raw_summary, flags=re.DOTALL).strip()  # Remove <think> section\n            cleaned_summary = re.sub(r\"(###.*?:|Critical Points:|Key Points:)\", \"\", cleaned_summary, flags=re.DOTALL).strip()\n\n            return cleaned_summary\n        else:\n            return \"Error: Response object does not have 'content' attribute\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n","metadata":{"id":"ZDCkfECBnU51","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.500410Z","iopub.execute_input":"2025-05-08T19:19:18.500641Z","iopub.status.idle":"2025-05-08T19:19:18.505663Z","shell.execute_reply.started":"2025-05-08T19:19:18.500625Z","shell.execute_reply":"2025-05-08T19:19:18.504918Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def summarize_text_Arabic(text, llm):\n    prompt = (f\"Summarize the following text in Egyptian Arabic while preserving English terms as they are: \\n{text}\")\n    try:\n        response = llm.invoke(prompt)\n\n        # Access and clean the response content\n        if hasattr(response, 'content'):\n            raw_summary = response.content  # Extract content\n            cleaned_summary = re.sub(r\"<think>.*?</think>\", \"\", raw_summary, flags=re.DOTALL).strip()  # Remove <think> section\n            cleaned_summary = re.sub(r\"(###.*?:|Critical Points:|Key Points:)\", \"\", cleaned_summary, flags=re.DOTALL).strip()\n\n            return cleaned_summary\n        else:\n            return \"Error: Response object does not have 'content' attribute\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n","metadata":{"id":"sk-QisFezB4q","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.506564Z","iopub.execute_input":"2025-05-08T19:19:18.507050Z","iopub.status.idle":"2025-05-08T19:19:18.524095Z","shell.execute_reply.started":"2025-05-08T19:19:18.507025Z","shell.execute_reply":"2025-05-08T19:19:18.523457Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from bs4 import BeautifulSoup\n\ndef extract_text_from_html(file_path):\n    \"\"\"Extract text content from an HTML file.\"\"\"\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        html_content = f.read()\n    soup = BeautifulSoup(html_content, \"html.parser\")\n    return soup.get_text()","metadata":{"id":"ZUUrSvNbuwgj","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.524935Z","iopub.execute_input":"2025-05-08T19:19:18.525115Z","iopub.status.idle":"2025-05-08T19:19:18.538732Z","shell.execute_reply.started":"2025-05-08T19:19:18.525102Z","shell.execute_reply":"2025-05-08T19:19:18.538157Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import tiktoken\ndef chunk_text(text, max_tokens=1000):\n    \"\"\"Split text into token-sized chunks.\"\"\"\n    encoding = tiktoken.get_encoding(\"cl100k_base\")\n    tokens = encoding.encode(text)\n    chunks = []\n    for i in range(0, len(tokens), max_tokens):\n        chunks.append(encoding.decode(tokens[i:i + max_tokens]))\n    return chunks","metadata":{"id":"n9HoDY0Ru47g","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.539774Z","iopub.execute_input":"2025-05-08T19:19:18.540012Z","iopub.status.idle":"2025-05-08T19:19:18.554674Z","shell.execute_reply.started":"2025-05-08T19:19:18.539988Z","shell.execute_reply":"2025-05-08T19:19:18.554059Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def summarize_large_file_English(file_path, output_file=\"The_summary_of_session_English.txt\", max_tokens=1000):\n\n    with open(file_path , 'r') as file:\n      text = file.read()\n\n    chunks = chunk_text(text, max_tokens=max_tokens)\n    summaries = []\n\n    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n        for i, chunk in enumerate(chunks, start=1):\n            summary = summarize_text_English(chunk, llm)\n\n            summary = re.sub(r\"^(.*?):\", r\"**\\1**:\", summary, flags=re.MULTILINE)\n            summary = re.split(r'(?<=[.!?])\\s+', summary)\n            summary = \"\\n\".join(summary).strip()\n\n            summaries.append(summary)\n            file.write(summary + \"\\n\\n \"+\"*******************************************************************************\\n\\n\")\n\n","metadata":{"id":"4AEJkRLT8IFZ","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.555395Z","iopub.execute_input":"2025-05-08T19:19:18.555630Z","iopub.status.idle":"2025-05-08T19:19:18.574319Z","shell.execute_reply.started":"2025-05-08T19:19:18.555616Z","shell.execute_reply":"2025-05-08T19:19:18.573627Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def summarize_large_file_Arabic(file_path, output_file=\"The_summary_of_session_Arabic.txt\", max_tokens=1000):\n\n    with open(file_path , 'r') as file:\n      text = file.read()\n\n    chunks = chunk_text(text, max_tokens=max_tokens)\n    summaries = []\n\n    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n        for i, chunk in enumerate(chunks, start=1):\n            summary = summarize_text_Arabic(chunk, llm)\n\n            summary = re.sub(r\"^(.*?):\", r\"**\\1**:\", summary, flags=re.MULTILINE)\n            summary = re.split(r'(?<=[.!?])\\s+', summary)\n            summary = \"\\n\".join(summary).strip()\n\n            summaries.append(summary)\n            file.write(summary + \"\\n\\n \"+\"*******************************************************************************\\n\\n\")\n\n","metadata":{"id":"r-_XXS9Azcwp","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.576486Z","iopub.execute_input":"2025-05-08T19:19:18.576707Z","iopub.status.idle":"2025-05-08T19:19:18.591890Z","shell.execute_reply.started":"2025-05-08T19:19:18.576692Z","shell.execute_reply":"2025-05-08T19:19:18.591299Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"summarize_large_file_English(\"/kaggle/working/full_transcription.txt\")","metadata":{"id":"7eF9DwJS5RXU","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:19:18.592435Z","iopub.execute_input":"2025-05-08T19:19:18.592680Z","iopub.status.idle":"2025-05-08T19:28:47.995833Z","shell.execute_reply.started":"2025-05-08T19:19:18.592665Z","shell.execute_reply":"2025-05-08T19:28:47.995099Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"summarize_large_file_Arabic(\"/kaggle/working/full_transcription.txt\")","metadata":{"id":"1Wak4cnO8IH7","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:28:47.996604Z","iopub.execute_input":"2025-05-08T19:28:47.996878Z","iopub.status.idle":"2025-05-08T19:42:21.467380Z","shell.execute_reply.started":"2025-05-08T19:28:47.996855Z","shell.execute_reply":"2025-05-08T19:42:21.466837Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"# **Create a Quick Quiz**","metadata":{"id":"A2HAdP1h5WmQ"}},{"cell_type":"markdown","source":"### Creata Complex Questions","metadata":{"id":"j9Ec2o_N6EvY"}},{"cell_type":"code","source":"prompt_template = \"\"\"\nf Generate three complex, analytical questions from the following text: {text}\n\"\"\"\nprompt = PromptTemplate(input_variables=[\"text\"], template=prompt_template)","metadata":{"id":"fYaIMZhQ6kfb","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:21.468233Z","iopub.execute_input":"2025-05-08T19:42:21.468791Z","iopub.status.idle":"2025-05-08T19:42:21.472706Z","shell.execute_reply.started":"2025-05-08T19:42:21.468764Z","shell.execute_reply":"2025-05-08T19:42:21.471969Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def complex_questions(input_text):\n  chain = LLMChain(llm=llm, prompt=prompt)\n  questions = chain.run(text=input_text)\n\n  cleaned_questions = re.sub(r\"<think>.*?</think>\", \"\", questions, flags=re.DOTALL).strip() # Remove <think> section\n\n  return cleaned_questions","metadata":{"id":"CbTYKvFS8ISM","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:21.473516Z","iopub.execute_input":"2025-05-08T19:42:21.473722Z","iopub.status.idle":"2025-05-08T19:42:21.489054Z","shell.execute_reply.started":"2025-05-08T19:42:21.473708Z","shell.execute_reply":"2025-05-08T19:42:21.488291Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"### create simple questions","metadata":{"id":"bQKNQip887vA"}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"valhalla/t5-base-e2e-qg\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"valhalla/t5-base-e2e-qg\")","metadata":{"id":"X4oeggjA8kF7","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:21.489842Z","iopub.execute_input":"2025-05-08T19:42:21.490021Z","iopub.status.idle":"2025-05-08T19:42:23.012496Z","shell.execute_reply.started":"2025-05-08T19:42:21.490008Z","shell.execute_reply":"2025-05-08T19:42:23.011978Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def simple_questions(text):\n  input_text = f\"generate question: {text} </s>\"\n\n  # Tokenize with explicit max_length and truncation\n  inputs = tokenizer(\n      input_text,\n      return_tensors=\"pt\",\n      padding=\"max_length\",\n      truncation=True,\n      max_length=512  # Adjust this value as needed\n  )\n\n  # Generate the question\n  outputs = model.generate(\n      input_ids=inputs[\"input_ids\"],\n      attention_mask=inputs[\"attention_mask\"],\n      max_length=64,\n      num_beams=5,\n      num_return_sequences=1,\n      repetition_penalty=2.0,\n      no_repeat_ngram_size=3\n  )\n\n  # Decode and print the generated question\n  question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n  return question","metadata":{"id":"UNEa1VhP8QiI","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:23.013183Z","iopub.execute_input":"2025-05-08T19:42:23.013355Z","iopub.status.idle":"2025-05-08T19:42:23.018109Z","shell.execute_reply.started":"2025-05-08T19:42:23.013341Z","shell.execute_reply":"2025-05-08T19:42:23.017329Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"### extact answer","metadata":{"id":"-BxLSUcu8_2Z"}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\n\nMODEL_NAME = \"google/flan-t5-large\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)","metadata":{"id":"eIT3WR678Dty","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:23.018801Z","iopub.execute_input":"2025-05-08T19:42:23.019442Z","iopub.status.idle":"2025-05-08T19:42:24.003159Z","shell.execute_reply.started":"2025-05-08T19:42:23.019420Z","shell.execute_reply":"2025-05-08T19:42:24.002366Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def extract_answers(text,question):\n  # Prepare the input text\n  input_text = f\"question: {question} context: {text}\"\n\n  # Tokenize the input\n  inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\n  # Generate the answer\n  outputs = model.generate(inputs, max_length=512, num_beams=5, early_stopping=True)\n\n  # Decode and print the answer\n  answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n  return answer\n","metadata":{"id":"BkZeVwM18lB2","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:24.004098Z","iopub.execute_input":"2025-05-08T19:42:24.004300Z","iopub.status.idle":"2025-05-08T19:42:24.008885Z","shell.execute_reply.started":"2025-05-08T19:42:24.004285Z","shell.execute_reply":"2025-05-08T19:42:24.008077Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import re\ndef Questions_and_Answers(file_path, output_file=\"Questions_Answers.txt\", max_tokens=500):\n\n    with open(file_path , 'r') as file:\n      text = file.read()\n\n    sections = [section.strip() for section in text.split(\"*******************************************************************************\") if section.strip()]\n    chunks = [section.split(\"\\n\") for section in sections]\n\n    QandA = []\n\n    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n        for chunk in chunks:\n            \n            complex_Questions = complex_questions(chunk)\n            complex_Questions = complex_Questions.split('<sep>')\n            complex_Questions = [question.strip() for question in complex_Questions if question.strip()]\n            \n            simple_Questions  = simple_questions(chunk)\n            simple_Questions = simple_Questions.split('<sep>')\n            simple_Questions = [question.strip() for question in simple_Questions if question.strip()]\n            \n            for Q in complex_Questions:\n                  file.write(\"Complex_Question\\n\"+Q+'\\n')\n                  A = extract_answers(chunk,Q)\n                  file.write(\"Answer\\n\"+A+'\\n*********************************************\\n')\n\n            for Q in simple_Questions:\n                  file.write(\"Simple_Question\\n\"+Q+'\\n')\n                  A = extract_answers(chunk,Q)\n                  file.write(\"Answer\\n\"+A+'\\n*********************************************\\n')","metadata":{"id":"TRMx44fL8IVu","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:24.009836Z","iopub.execute_input":"2025-05-08T19:42:24.010186Z","iopub.status.idle":"2025-05-08T19:42:24.027588Z","shell.execute_reply.started":"2025-05-08T19:42:24.010163Z","shell.execute_reply":"2025-05-08T19:42:24.026968Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"Questions_and_Answers(\"/kaggle/working/The_summary_of_session_English.txt\")\n#Questions_and_Answers(\"/kaggle/input/summary/transformers/default/1/The_summary_of_session_English (1).txt\")","metadata":{"id":"4W-SpM8m3nKu","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:24.028201Z","iopub.execute_input":"2025-05-08T19:42:24.028409Z","iopub.status.idle":"2025-05-08T20:17:52.453030Z","shell.execute_reply.started":"2025-05-08T19:42:24.028394Z","shell.execute_reply":"2025-05-08T20:17:52.452353Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# Comapre Answers","metadata":{"id":"Cs4YA3lS8Oml"}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nmodel = SentenceTransformer('paraphrase-MiniLM-L6-v2')","metadata":{"id":"dBhIb5716akx","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:17:52.453855Z","iopub.execute_input":"2025-05-08T20:17:52.454042Z","iopub.status.idle":"2025-05-08T20:17:53.847466Z","shell.execute_reply.started":"2025-05-08T20:17:52.454028Z","shell.execute_reply":"2025-05-08T20:17:53.846893Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"correct_answer = \"Overfitting occurs when a model is too complex and fits the training data too closely, often performing poorly on new data.\"\nstudent_answer = \"When a model becomes overly complex and fits too much to training data.\"\n\n\n\ncorrect_embedding = model.encode([correct_answer])\nstudent_embedding = model.encode([student_answer])\n#huggingface_hub\n\nsimilarity_score = cosine_similarity(correct_embedding, student_embedding)[0][0]\n\n\nif similarity_score > 0.80:\n    print(\"إجابة الطالب صحيحة بنسبة\", similarity_score * 100, \"%\")\nelse:\n    print(\"إجابة الطالب غير صحيحة. التشابه:\", similarity_score * 100, \"%\")\n","metadata":{"id":"fDebfr-y8Lek","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:17:53.848292Z","iopub.execute_input":"2025-05-08T20:17:53.848525Z","iopub.status.idle":"2025-05-08T20:17:53.896699Z","shell.execute_reply.started":"2025-05-08T20:17:53.848508Z","shell.execute_reply":"2025-05-08T20:17:53.895935Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1589d38fd6f4c77a529500e990a9769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"540af3ffe6dc42589722467b468846b0"}},"metadata":{}},{"name":"stdout","text":"إجابة الطالب صحيحة بنسبة 81.4844012260437 %\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"## **Extract Notes**","metadata":{"id":"HnIYckAAhucq"}},{"cell_type":"code","source":"","metadata":{"id":"nRVE7hSNh0oO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YfyeZnpwh0e6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"P-oXxEJoh0bd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"0MTIwC8Oh0YY","trusted":true},"outputs":[],"execution_count":null}]}